{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import gen_array_ops\n",
    "from tensorflow.python.framework import ops\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxout(inputs, num_units, axis):\n",
    "    inputs = ops.convert_to_tensor(inputs)\n",
    "    shape = inputs.get_shape().as_list()\n",
    "    num_channels = shape[axis]\n",
    "    shape[axis] = -1\n",
    "    shape += [num_channels // num_units]\n",
    "    for i in range(len(shape)):\n",
    "        if shape[i] is None:\n",
    "                shape[i] = gen_array_ops.shape(inputs)[i]\n",
    "    outputs = math_ops.reduce_max(gen_array_ops.reshape(inputs, shape), -1, keep_dims=False)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.resize(cv2.cvtColor(cv2.imread(\"img/canon.jpg\"), cv2.COLOR_BGR2RGB), (16, 16))\n",
    "img_tensor = tf.reshape(tf.convert_to_tensor(img, dtype=tf.float32), [1, 16, 16, 3])\n",
    "filters_1 = tf.reshape(tf.constant(np.load(\"numpy_parameters/conv1_0.npy\"), name=\"filters_1\"), [5, 5, 3, 20])\n",
    "bias_1 = tf.constant(np.load(\"numpy_parameters/conv1_1.npy\"), name=\"bias_1\")\n",
    "conv_1 = tf.nn.conv2d(img_tensor, filters_1, [1, 1, 1, 1], padding=\"VALID\")\n",
    "output_1 =  tf.nn.relu(tf.nn.bias_add(conv_1, bias_1))\n",
    "reshape_1 = tf.reshape(output_1, [1, 12, 12, 20])\n",
    "max_1 = maxout(reshape_1, 4, 3)\n",
    "reshape_2 = tf.reshape(max_1, [1, 12, 12, 4])\n",
    "filters_2 = tf.reshape(tf.constant(np.load(\"numpy_parameters/conv2-1x1_0.npy\"), name=\"filters_2\"), [1, 1, 4, 16])\n",
    "bias_2 = tf.constant(np.load(\"numpy_parameters/conv2-1x1_1.npy\"), name=\"bias_2\")\n",
    "conv_2 = tf.nn.conv2d(reshape_2, filters_2, [1, 1, 1, 1], padding=\"VALID\")\n",
    "output_2 =  tf.nn.relu(tf.nn.bias_add(conv_2, bias_2))\n",
    "filters_3 = tf.reshape(tf.constant(np.load(\"numpy_parameters/conv2-3x3_0.npy\"), name=\"filters_3\"), [3, 3, 4, 16])\n",
    "bias_3 = tf.constant(np.load(\"numpy_parameters/conv2-3x3_1.npy\"), name=\"bias_3\")\n",
    "conv_3 = tf.nn.conv2d(reshape_2, filters_3, [1, 1, 1, 1], padding=\"SAME\")\n",
    "output_3 =  tf.nn.relu(tf.nn.bias_add(conv_3, bias_3))\n",
    "filters_4 = tf.reshape(tf.constant(np.load(\"numpy_parameters/conv2-5x5_0.npy\"), name=\"filters_4\"), [5, 5, 4, 16])\n",
    "bias_4 = tf.constant(np.load(\"numpy_parameters/conv2-5x5_1.npy\"), name=\"bias_4\")\n",
    "conv_4 = tf.nn.conv2d(reshape_2, filters_4, [1, 1, 1, 1], padding=\"SAME\")\n",
    "output_4 =  tf.nn.relu(tf.nn.bias_add(conv_4, bias_4))\n",
    "filters_5 = tf.reshape(tf.constant(np.load(\"numpy_parameters/conv2-7x7_0.npy\"), name=\"filters_5\"), [7, 7, 4, 16])\n",
    "bias_5 = tf.constant(np.load(\"numpy_parameters/conv2-7x7_1.npy\"), name=\"bias_5\")\n",
    "conv_5 = tf.nn.conv2d(reshape_2, filters_5, [1, 1, 1, 1], padding=\"SAME\")\n",
    "output_5 =  tf.nn.relu(tf.nn.bias_add(conv_5, bias_5))\n",
    "output_6 = tf.concat([output_2, output_3, output_4, output_5], axis=3)\n",
    "output_7 = tf.nn.relu(output_6)\n",
    "output_8  = tf.nn.max_pool(output_7, [1, 8, 8, 1], [1, 1, 1, 1], padding='VALID')\n",
    "filters_6 = np.load(\"numpy_parameters/ip1_0.npy\").reshape((5, 5, 64, 1))\n",
    "output_9 = tf.nn.conv2d(output_8, filters_6, [1, 1, 1, 1], padding=\"VALID\")\n",
    "#transmission = None\n",
    "with tf.Session() as sess:\n",
    "    output_9 = sess.run(output_9)\n",
    "    print(output_9.shape)\n",
    "    #output_8, transmission = sess.run([output_8, output_9])\n",
    "    #print(output_8.shape)\n",
    "    #transmission = transmission.reshape(525, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransmissionEstimate(im_path, height, width): \n",
    "    img = cv2.resize(cv2.cvtColor(cv2.imread(\"img/canon.jpg\"), cv2.COLOR_BGR2RGB), (320,320))\n",
    "    print(img.shape)\n",
    "    img  = (img * 1.0) / (255 * 1.0)\n",
    "    npad = ((7,8), (7,8), (0,0))\n",
    "    img = np.pad(img, npad, 'symmetric')\n",
    "    print(img.shape)\n",
    "    img_tensor = tf.reshape(tf.convert_to_tensor(img, dtype=tf.float32), [1, height+15, width+15, 3])\n",
    "    print(img_tensor)\n",
    "    filters_1 = tf.reshape(tf.constant(np.load(\"numpy_parameters/conv1_0.npy\"), name=\"filters_1\"), [5, 5, 3, 20])\n",
    "    bias_1 = tf.constant(np.load(\"numpy_parameters/conv1_1.npy\"), name=\"bias_1\")\n",
    "    conv_1 = tf.nn.conv2d(img_tensor, filters_1, [1, 1, 1, 1], padding=\"VALID\")\n",
    "    output_1 =  tf.nn.relu(tf.nn.bias_add(conv_1, bias_1))\n",
    "    \n",
    "    print(output_1)\n",
    "    \n",
    "    reshape_1 = tf.reshape(output_1, [1, height+11, width+11, 20])\n",
    "    max_1 = maxout(reshape_1, 4, 3)\n",
    "    reshape_2 = tf.reshape(max_1, [1, height+11, width+11, 4])\n",
    "    print(reshape_2)\n",
    "    \n",
    "    filters_2 = tf.reshape(tf.constant(np.load(\"numpy_parameters/conv2-1x1_0.npy\"), name=\"filters_2\"), [1, 1, 4, 16])\n",
    "    bias_2 = tf.constant(np.load(\"numpy_parameters/conv2-1x1_1.npy\"), name=\"bias_2\")\n",
    "    conv_2 = tf.nn.conv2d(reshape_2, filters_2, [1, 1, 1, 1], padding=\"VALID\")\n",
    "    output_2 =  tf.nn.relu(tf.nn.bias_add(conv_2, bias_2))\n",
    "    print(output_2)\n",
    "    \n",
    "    filters_3 = tf.reshape(tf.constant(np.load(\"numpy_parameters/conv2-3x3_0.npy\"), name=\"filters_3\"), [3, 3, 4, 16])\n",
    "    bias_3 = tf.constant(np.load(\"numpy_parameters/conv2-3x3_1.npy\"), name=\"bias_3\")\n",
    "    conv_3 = tf.nn.conv2d(reshape_2, filters_3, [1, 1, 1, 1], padding=\"SAME\")\n",
    "    output_3 =  tf.nn.relu(tf.nn.bias_add(conv_3, bias_3))\n",
    "    \n",
    "    filters_4 = tf.reshape(tf.constant(np.load(\"numpy_parameters/conv2-5x5_0.npy\"), name=\"filters_4\"), [5, 5, 4, 16])\n",
    "    bias_4 = tf.constant(np.load(\"numpy_parameters/conv2-5x5_1.npy\"), name=\"bias_4\")\n",
    "    conv_4 = tf.nn.conv2d(reshape_2, filters_4, [1, 1, 1, 1], padding=\"SAME\")\n",
    "    output_4 =  tf.nn.relu(tf.nn.bias_add(conv_4, bias_4))\n",
    "    \n",
    "    filters_5 = tf.reshape(tf.constant(np.load(\"numpy_parameters/conv2-7x7_0.npy\"), name=\"filters_5\"), [7, 7, 4, 16])\n",
    "    bias_5 = tf.constant(np.load(\"numpy_parameters/conv2-7x7_1.npy\"), name=\"bias_5\")\n",
    "    conv_5 = tf.nn.conv2d(reshape_2, filters_5, [1, 1, 1, 1], padding=\"SAME\")\n",
    "    output_5 =  tf.nn.relu(tf.nn.bias_add(conv_5, bias_5))\n",
    "    \n",
    "    output_6 = tf.concat([output_4, output_3, output_4, output_5], axis=3)\n",
    "    output_7 = tf.nn.relu(output_6)\n",
    "    print(output_6)\n",
    "    output_8  = tf.nn.max_pool(output_7, [1, 8, 8, 1], [1, 1, 1, 1], padding='VALID')\n",
    "    \n",
    "    print(output_8)\n",
    "    \n",
    "    final_conv_1 = tf.layers.conv2d(inputs=output_8,\n",
    "                                    filters=1,\n",
    "                                    strides=(4, 4),\n",
    "                                    kernel_size=[8, 8],\n",
    "                                    padding=\"VALID\",\n",
    "                                    activation=tf.nn.relu,\n",
    "                                    name=\"DehazeNet/final_conv_1\")\n",
    "    \n",
    "    #filters_6 = tf.reshape(tf.constant(np.load(\"numpy_parameters/ip1_0.npy\"), name=\"filters_6\"), [5, 5, 64, 1])\n",
    "    #bias_6 = tf.constant(np.load(\"numpy_parameters/ip1_1.npy\"), name=\"bias_6\")\n",
    "    #conv_6 = tf.nn.conv2d(output_8, filters_6, [1, 2, 2, 1], padding=\"VALID\")\n",
    "    \n",
    "    #final_output = tf.nn.relu(tf.nn.bias_add(conv_6, bias_6))\n",
    "    \n",
    "    final_conv_2 = tf.layers.conv2d(inputs=tf.nn.max_pool(final_conv_1, [1, 8, 8, 1], [1, 8, 8, 1], padding='VALID'),\n",
    "                                    filters=1,\n",
    "                                    strides=(4, 4),\n",
    "                                    kernel_size=[8, 8],\n",
    "                                    padding=\"VALID\",\n",
    "                                    activation=tf.nn.relu,\n",
    "                                    name=\"DehazeNet/final_conv_2\")\n",
    "    \n",
    "    #final_conv_3 = tf.layers.conv2d(inputs=tf.nn.max_pool(final_conv, [1, 8, 8, 1], [1, 2, 2, 1], padding='VALID'),\n",
    "    #                                filters=1,\n",
    "    #                                strides=(2, 2),\n",
    "    #                                kernel_size=[4, 4],\n",
    "    #                                padding=\"VALID\",\n",
    "    #                                activation=tf.nn.relu,\n",
    "    #                                name=\"DehazeNet/final_conv_2\")\n",
    "    transmission = None\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        final_output_numpy = sess.run(final_conv_2)\n",
    "        print(final_output_numpy.shape)\n",
    "    return transmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DarkChannel(im,sz):\n",
    "    b,g,r = cv2.split(im)\n",
    "    dc = cv2.min(cv2.min(r,g),b)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(sz,sz))\n",
    "    dark = cv2.erode(dc,kernel)\n",
    "    return dark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AtmLight(im,dark):\n",
    "    [h,w] = im.shape[:2]\n",
    "    imsz = h*w\n",
    "    numpx = int(max(math.floor(imsz/1000),1))\n",
    "    darkvec = dark.reshape(imsz,1)\n",
    "    imvec = im.reshape(imsz,3)\n",
    "    indices = darkvec.argsort()\n",
    "    indices = indices[imsz-numpx::]\n",
    "    atmsum = np.zeros([1,3])\n",
    "    for ind in range(1,numpx):\n",
    "        atmsum = atmsum + imvec[indices[ind]]\n",
    "    A = atmsum / numpx\n",
    "    return A\n",
    "\n",
    "def Guidedfilter(im,p,r,eps):\n",
    "    mean_I = cv2.boxFilter(im,cv2.CV_64F,(r,r))\n",
    "    mean_p = cv2.boxFilter(p, cv2.CV_64F,(r,r))\n",
    "    mean_Ip = cv2.boxFilter(im*p,cv2.CV_64F,(r,r))\n",
    "    cov_Ip = mean_Ip - mean_I*mean_p\n",
    "    mean_II = cv2.boxFilter(im*im,cv2.CV_64F,(r,r))\n",
    "    var_I   = mean_II - mean_I*mean_I\n",
    "    a = cov_Ip/(var_I + eps)\n",
    "    b = mean_p - a*mean_I\n",
    "    mean_a = cv2.boxFilter(a,cv2.CV_64F,(r,r))\n",
    "    mean_b = cv2.boxFilter(b,cv2.CV_64F,(r,r))\n",
    "    q = mean_a*im + mean_b\n",
    "    return q\n",
    "\n",
    "def TransmissionRefine(im,et):\n",
    "    gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    gray = np.float64(gray)/255\n",
    "    r = 60\n",
    "    eps = 0.0001\n",
    "    t = Guidedfilter(gray,et,r,eps)\n",
    "    return t\n",
    "\n",
    "def Recover(im,t,A,tx = 0.1):\n",
    "    res = np.empty(im.shape,im.dtype)\n",
    "    t = cv2.max(t,tx)\n",
    "    for ind in range(0,3):\n",
    "        res[:,:,ind] = (im[:,:,ind]-A[0,ind])/t + A[0,ind]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 320, 3)\n",
      "(335, 335, 3)\n",
      "Tensor(\"Reshape:0\", shape=(1, 335, 335, 3), dtype=float32)\n",
      "Tensor(\"Relu:0\", shape=(1, 331, 331, 20), dtype=float32)\n",
      "Tensor(\"Reshape_4:0\", shape=(1, 331, 331, 4), dtype=float32)\n",
      "Tensor(\"Relu_1:0\", shape=(1, 331, 331, 16), dtype=float32)\n",
      "Tensor(\"concat:0\", shape=(1, 331, 331, 64), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(1, 324, 324, 64), dtype=float32)\n",
      "(1, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "im_path = \"img/canon.jpg\"\n",
    "#src = cv2.resize(cv2.imread(im_path))\n",
    "\n",
    "#height = src.shape[0]\n",
    "#width = src.shape[1]\n",
    "#print(height)\n",
    "#print(width)\n",
    "#I = src/255.0\n",
    "#dark = DarkChannel(I,15)\n",
    "#A = AtmLight(I,dark)\n",
    "te = TransmissionEstimate(im_path, 320, 320)\n",
    "#t = TransmissionRefine(src,te)\n",
    "#J = Recover(I,t,A,0.1)\n",
    "#cv2.imshow('TransmissionEstimate',te)\n",
    "#cv2.imshow('Origin',src)\n",
    "#cv2.imshow('Dehaze',J)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
