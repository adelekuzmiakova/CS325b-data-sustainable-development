{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import caffe\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EditFcnProto(templateFile, height, width):\n",
    "    with open(templateFile, 'r') as ft:\n",
    "        template = ft.read()\n",
    "        outFile = 'DehazeNet/DehazeNetFcn.prototxt'\n",
    "        with open(outFile, 'w') as fd:\n",
    "            fd.write(template.format(height_15=height+15, width_15=width+15, height_11=height+11, width_11=width+11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "templateFile = 'DehazeNet/DehazeFcnTemplate.prototxt'\n",
    "EditFcnProto(templateFile, 525,600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525, 600, 3)\n",
      "(525, 600, 3)\n",
      "(540, 615, 3)\n",
      "(1, 3, 540, 615)\n",
      "(540, 615, 3)\n",
      "(1, 3, 540, 615)\n"
     ]
    }
   ],
   "source": [
    "caffe.set_mode_cpu()\n",
    "net = caffe.Net('DehazeNet/DehazeNet.prototxt', 'DehazeNet/DehazeNet.caffemodel', caffe.TEST)\n",
    "net_full_conv = caffe.Net('DehazeNet/DehazeNetFcn.prototxt', 'DehazeNet/DehazeNet.caffemodel', caffe.TEST)\n",
    "net_full_conv.params['ip1-conv'][0].data.flat = net.params['ip1'][0].data.flat\n",
    "net_full_conv.params['ip1-conv'][1].data[...] = net.params['ip1'][1].data\n",
    "im = caffe.io.load_image(\"DehazeNet/img/canon.jpg\") * 255\n",
    "print(im.shape)\n",
    "npad = ((7,8), (7,8), (0,0))\n",
    "print(im.shape)\n",
    "im = np.pad(im, npad, 'symmetric')\n",
    "print(im.shape)\n",
    "transformers = caffe.io.Transformer({'data': net_full_conv.blobs['data'].data.shape})\n",
    "print(net_full_conv.blobs['data'].data.shape)\n",
    "transformers.set_transpose('data', (2,0,1))\n",
    "transformers.set_channel_swap('data', (2,1,0))\n",
    "print(im.shape)\n",
    "print(np.array([transformers.preprocess('data', im-0.2)]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "def extract_caffe_model(model, weights, output_path):\n",
    "    \"\"\"extract caffe model's parameters to numpy array, and write them to files\n",
    "        Args:\n",
    "            model: path of '.prototxt'\n",
    "            weights: path of '.caffemodel'\n",
    "            output_path: output path of numpy params \n",
    "        Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    net = caffe.Net(model, caffe.TEST)\n",
    "    net.copy_from(weights)\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "        \n",
    "    for item in net.params.items():\n",
    "        name, layer = item\n",
    "        \n",
    "        num = 0\n",
    "        for p in net.params[name]:\n",
    "            np.save(output_path + '/' + str(name).replace('/', '-') + '_' + str(num), p.data)\n",
    "            num += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = \"DehazeNet/DehazeNetFcn.prototxt\"\n",
    "path_to_weights = \"DehazeNet/DehazeNet.caffemodel\"\n",
    "extract_caffe_model(path_to_model, path_to_weights, \"DehazeNet/numpy_parameters_for_updated_template\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"DehazeNet/numpy_parameters_for_updated_template\" + '/' + 'ip1-conv-transformed' + '_' + str(0), net_full_conv.params['ip1-conv'][0].data)\n",
    "np.save(\"DehazeNet/numpy_parameters_for_updated_template\" + '/' + 'ip1-conv-transformed' + '_' + str(1), net_full_conv.params['ip1-conv'][1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 5, 5)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "print(np.load(\"DehazeNet/numpy_parameters_for_updated_template/ip1-conv-transformed_0.npy\").shape)\n",
    "print(np.load(\"DehazeNet/numpy_parameters_for_updated_template/ip1-conv-transformed_1.npy\").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-ad1a801d5487>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-ad1a801d5487>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Skip to content\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "VGG_MEAN = [103.939, 116.779, 123.68]\n",
    "\n",
    "\n",
    "class Vgg16:\n",
    "    def __init__(self, vgg16_npy_path=None):\n",
    "        if vgg16_npy_path is None:\n",
    "            path = inspect.getfile(Vgg16)\n",
    "            path = os.path.abspath(os.path.join(path, os.pardir))\n",
    "            path = os.path.join(path, \"vgg16.npy\")\n",
    "            vgg16_npy_path = path\n",
    "            print(path)\n",
    "\n",
    "        self.data_dict = np.load(vgg16_npy_path, encoding='latin1').item()\n",
    "        print(\"npy file loaded\")\n",
    "\n",
    "    def build(self, rgb):\n",
    "        \"\"\"\n",
    "        load variable from npy to build the VGG\n",
    "        :param rgb: rgb image [batch, height, width, 3] values scaled [0, 1]\n",
    "        \"\"\"\n",
    "\n",
    "        start_time = time.time()\n",
    "        print(\"build model started\")\n",
    "        rgb_scaled = rgb * 255.0\n",
    "\n",
    "        # Convert RGB to BGR\n",
    "        red, green, blue = tf.split(axis=3, num_or_size_splits=3, value=rgb_scaled)\n",
    "        assert red.get_shape().as_list()[1:] == [224, 224, 1]\n",
    "        assert green.get_shape().as_list()[1:] == [224, 224, 1]\n",
    "        assert blue.get_shape().as_list()[1:] == [224, 224, 1]\n",
    "        bgr = tf.concat(axis=3, values=[\n",
    "            blue - VGG_MEAN[0],\n",
    "            green - VGG_MEAN[1],\n",
    "            red - VGG_MEAN[2],\n",
    "        ])\n",
    "        assert bgr.get_shape().as_list()[1:] == [224, 224, 3]\n",
    "\n",
    "        self.conv1_1 = self.conv_layer(bgr, \"conv1_1\")\n",
    "        self.conv1_2 = self.conv_layer(self.conv1_1, \"conv1_2\")\n",
    "        self.pool1 = self.max_pool(self.conv1_2, 'pool1')\n",
    "\n",
    "        self.conv2_1 = self.conv_layer(self.pool1, \"conv2_1\")\n",
    "        self.conv2_2 = self.conv_layer(self.conv2_1, \"conv2_2\")\n",
    "        self.pool2 = self.max_pool(self.conv2_2, 'pool2')\n",
    "\n",
    "        self.conv3_1 = self.conv_layer(self.pool2, \"conv3_1\")\n",
    "        self.conv3_2 = self.conv_layer(self.conv3_1, \"conv3_2\")\n",
    "        self.conv3_3 = self.conv_layer(self.conv3_2, \"conv3_3\")\n",
    "        self.pool3 = self.max_pool(self.conv3_3, 'pool3')\n",
    "\n",
    "        self.conv4_1 = self.conv_layer(self.pool3, \"conv4_1\")\n",
    "        self.conv4_2 = self.conv_layer(self.conv4_1, \"conv4_2\")\n",
    "        self.conv4_3 = self.conv_layer(self.conv4_2, \"conv4_3\")\n",
    "        self.pool4 = self.max_pool(self.conv4_3, 'pool4')\n",
    "\n",
    "        self.conv5_1 = self.conv_layer(self.pool4, \"conv5_1\")\n",
    "        self.conv5_2 = self.conv_layer(self.conv5_1, \"conv5_2\")\n",
    "        self.conv5_3 = self.conv_layer(self.conv5_2, \"conv5_3\")\n",
    "        self.pool5 = self.max_pool(self.conv5_3, 'pool5')\n",
    "\n",
    "        self.fc6 = self.fc_layer(self.pool5, \"fc6\")\n",
    "        assert self.fc6.get_shape().as_list()[1:] == [4096]\n",
    "        self.relu6 = tf.nn.relu(self.fc6)\n",
    "\n",
    "        self.fc7 = self.fc_layer(self.relu6, \"fc7\")\n",
    "        self.relu7 = tf.nn.relu(self.fc7)\n",
    "\n",
    "        self.fc8 = self.fc_layer(self.relu7, \"fc8\")\n",
    "\n",
    "        self.prob = tf.nn.softmax(self.fc8, name=\"prob\")\n",
    "\n",
    "        self.data_dict = None\n",
    "        print((\"build model finished: %ds\" % (time.time() - start_time)))\n",
    "\n",
    "    def avg_pool(self, bottom, name):\n",
    "        return tf.nn.avg_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
    "\n",
    "    def max_pool(self, bottom, name):\n",
    "        return tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
    "\n",
    "    def conv_layer(self, bottom, name):\n",
    "        with tf.variable_scope(name):\n",
    "            filt = self.get_conv_filter(name)\n",
    "\n",
    "            conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "            conv_biases = self.get_bias(name)\n",
    "            bias = tf.nn.bias_add(conv, conv_biases)\n",
    "\n",
    "            relu = tf.nn.relu(bias)\n",
    "            return relu\n",
    "\n",
    "    def fc_layer(self, bottom, name):\n",
    "        with tf.variable_scope(name):\n",
    "            shape = bottom.get_shape().as_list()\n",
    "            dim = 1\n",
    "            for d in shape[1:]:\n",
    "                dim *= d\n",
    "            x = tf.reshape(bottom, [-1, dim])\n",
    "\n",
    "            weights = self.get_fc_weight(name)\n",
    "            biases = self.get_bias(name)\n",
    "\n",
    "            # Fully connected layer. Note that the '+' operation automatically\n",
    "            # broadcasts the biases.\n",
    "            fc = tf.nn.bias_add(tf.matmul(x, weights), biases)\n",
    "\n",
    "            return fc\n",
    "\n",
    "    def get_conv_filter(self, name):\n",
    "        return tf.constant(self.data_dict[name][0], name=\"filter\")\n",
    "\n",
    "    def get_bias(self, name):\n",
    "        return tf.constant(self.data_dict[name][1], name=\"biases\")\n",
    "\n",
    "    def get_fc_weight(self, name):\n",
    "        return tf.constant(self.data_dict[name][0], name=\"weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
